{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "entrenamiento_red.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKLQBWwM/8hVEFzzUClJc1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eYrrkTZvemj"
      },
      "source": [
        "El objetivo de las siguientes funciones es entrenar una red neuronal capaz de predecir posiciones mediante diferencias temporales de tiempo arribo a micrófonos. Para el entrenamiento de la red se generan numéricamente grillas de puntos, se calculan los delays temporales esperados (más un error aleatorio) y se procede a al entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-1ToneivfyI"
      },
      "source": [
        "import numpy as np\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import random\n",
        "from tensorflow.keras.models import load_model\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vi01BYZv5-V"
      },
      "source": [
        "#Definimos la funciones que vamos a usar para generar datos de entrenamientos y testeo.\n",
        "\n",
        "\n",
        "def delays_entrenamiento(radio, paso):\n",
        "  total_samples = int(((2*radio)/paso)**2)\n",
        "  \n",
        "  \n",
        "  M1 = np.array([-3.5,  3.5, 0]) # así es mejor para introducir las posiciones de \n",
        "  M2 = np.array([-3.5, -3.5, 0]) # los MIC´s si no están en un cuadrado\n",
        "  M3 = np.array([ 3.5,  3.5, 0])\n",
        "  M4 = np.array([ 3.5, -3.5, 0])\n",
        "\n",
        "\n",
        "  #Otros Parámetros\n",
        "  v= 350.0 # velocidad del sonido\n",
        "  fs = 44100.0 # frecuencia de muestreo de las grabaciones\n",
        "  error = 2/fs\n",
        "  Z_min =0.5\n",
        "  Data = np.zeros([total_samples,6]) # delays para 4 MIC´s\n",
        "  XYZ = np.zeros([total_samples,3]) # posiciones\n",
        "  s=0\n",
        "  for i in range(0, int(np.sqrt(total_samples))): # esta es otra forma, Gabo construye para \n",
        "      for j in range(0, int(np.sqrt(total_samples))): # recorrer equiespaciado una grilla\n",
        "          for k in range(1,2): # alto del árbol\n",
        "              x=-radio + paso*i \n",
        "              y=-radio + paso*j  #pasos en la grilla de 2\n",
        "              z=Z_min*k\n",
        "                        \n",
        "              r1=math.sqrt((x-M1[0])**2+(y-M1[1])**2+(z-M1[2])**2)\n",
        "              r2=math.sqrt((x-M2[0])**2+(y-M2[1])**2+(z-M2[2])**2)\n",
        "              r3=math.sqrt((x-M3[0])**2+(y-M3[1])**2+(z-M3[2])**2)\n",
        "              r4=math.sqrt((x-M4[0])**2+(y-M4[1])**2+(z-M4[2])**2) # distancias a cada MIC\n",
        "                              \n",
        "              delta12=(1/v)*(r1-r2)+(error)*random.uniform(0,1)\n",
        "              delta13=(1/v)*(r1-r3)+(error)*random.uniform(0,1)\n",
        "              delta14=(1/v)*(r1-r4)+(error)*random.uniform(0,1)\n",
        "              delta23=(1/v)*(r2-r3)+(error)*random.uniform(0,1)\n",
        "              delta24=(1/v)*(r2-r4)+(error)*random.uniform(0,1)\n",
        "              delta34=(1/v)*(r3-r4)+(error)*random.uniform(0,1) # diferencias de tiempo, + un error en la cuantificacion\n",
        "              Data[s,0]=delta12; Data[s,1]=delta13; Data[s,2]=delta14;\n",
        "              Data[s,3]=delta23; Data[s,4]=delta24\n",
        "              Data[s,5]=delta34\n",
        "              XYZ[s,0]=x; XYZ[s,1]=y; XYZ[s,2]=z\n",
        "              s=s+1\n",
        "  return Data, XYZ, total_samples\n",
        "              \n",
        "           \n",
        "\n",
        "\n",
        "def delays_testeo(x,y,z):\n",
        "  M1 = np.array([-3.5,  3.5, 0]) # así es mejor para introducir las posiciones de\n",
        "  M2 = np.array([-3.5, -3.5, 0]) # los MIC´s si no están en un cuadrado\n",
        "  M3 = np.array([ 3.5,  3.5, 0])\n",
        "  M4 = np.array([ 3.5, -3.5, 0])\n",
        "  #Otros Parámetros\n",
        "  v= 350.0 # velocidad del sonido\n",
        "  fs = 44100.0 # frecuencia de muestreo de las grabaciones\n",
        "  error = 2/fs\n",
        "  Data = np.zeros([len(x),6]) # delays para 4 MIC´s\n",
        "  XYZ = np.zeros([len(x),3]) # posiciones\n",
        "\n",
        "  for i in range(len(x)):\n",
        "    r1=math.sqrt((x[i]-M1[0])**2+(y[i]-M1[1])**2+(z[i]-M1[2])**2)\n",
        "    r2=math.sqrt((x[i]-M2[0])**2+(y[i]-M2[1])**2+(z[i]-M2[2])**2)\n",
        "    r3=math.sqrt((x[i]-M3[0])**2+(y[i]-M3[1])**2+(z[i]-M3[2])**2)\n",
        "    r4=math.sqrt((x[i]-M4[0])**2+(y[i]-M4[1])**2+(z[i]-M4[2])**2) # distancias a cada MIC\n",
        "            \n",
        "    delta12=(1/v)*(r1-r2)+(error)*random.uniform(0,1)\n",
        "    delta13=(1/v)*(r1-r3)+(error)*random.uniform(0,1)\n",
        "    delta14=(1/v)*(r1-r4)+(error)*random.uniform(0,1)\n",
        "    delta23=(1/v)*(r2-r3)+(error)*random.uniform(0,1)\n",
        "    delta24=(1/v)*(r2-r4)+(error)*random.uniform(0,1)\n",
        "    delta34=(1/v)*(r3-r4)+(error)*random.uniform(0,1) # diferencias de tiempo, + un error en la cuantificacion\n",
        "    Data[i,0]=delta12; Data[i,1]=delta13; Data[i,2]=delta14;\n",
        "    Data[i,3]=delta23; Data[i,4]=delta24\n",
        "    Data[i,5]=delta34\n",
        "    XYZ[i,0]=x[i]; XYZ[i,1]=y[i]; XYZ[i,2]=z[i]\n",
        "  return Data, XYZ\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sCr8QRqz1LQ"
      },
      "source": [
        "Data, XYZ, total_samples= delays_entrenamiento(6,.35) #creo los delays de entrenamiento\n",
        "np.savetxt('/content/drive/MyDrive/RedGabo_Felipe & Constanza/Data.txt',Data,fmt = '%10.5f') #los guardo\n",
        "np.savetxt('/content/drive/MyDrive/RedGabo_Felipe & Constanza/XYZ.txt',XYZ,fmt = '%10.5f') #los cargo\n",
        "\n",
        "train_data=np.loadtxt('/content/drive/MyDrive/RedGabo_Felipe & Constanza/Data.txt') #asigno los train targets y train data\n",
        "train_targets=np.loadtxt('/content/drive/MyDrive/RedGabo_Felipe & Constanza/XYZ.txt')\n",
        "\n",
        "\n",
        "\n",
        "delays_medidos=np.zeros(train_data.shape[1])\n",
        "train_data.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OG2uZXE18Bb"
      },
      "source": [
        "#entrenamos la red\n",
        "def build_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(train_data.shape[1],)))\n",
        "    \n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(3))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# dio muy bien con 64 ...\n",
        "#modelx = build_model()\n",
        "#modelx.fit(train_data, train_targetsx,epochs=80, batch_size=16, verbose=0)\n",
        "#modely = build_model()\n",
        "#modely.fit(train_data, train_targetsy,epochs=80, batch_size=16, verbose=0)\n",
        "#modelz = build_model()\n",
        "#modelz.fit(train_data, train_targetsz,epochs=80, batch_size=16, verbose=0)\n",
        "\n",
        "k = 3 #4\n",
        "num_val_samples = len(train_data) // k\n",
        "num_epochs = 1000 #10\n",
        "all_mae_histories = []\n",
        "\n",
        "# para los x, los validation\n",
        "\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "         axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "         axis=0)\n",
        "    model = build_model()\n",
        "    history=model.fit(partial_train_data, partial_train_targets,\n",
        "                      validation_data=(val_data, val_targets),\n",
        "                      epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    \n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    mae_history = history.history['mae']\n",
        "    all_mae_histories.append(mae_history)\n",
        "\n",
        "model.save('/content/drive/MyDrive/RedGabo_Felipe & Constanza/(6412812864)_r.h5') #guarden el modelo en su Drive personal\n",
        "average_mae_history = [np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]\n",
        "\n",
        "\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history,'.')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.ylim(np.min(average_mae_history)-1,np.min(average_mae_history)+1)\n",
        "plt.hlines(np.min(average_mae_history),0,num_epochs,colors='r', linestyles='dashed')\n",
        "plt.show()\n",
        "print('El MAE minimo es: ',np.min(average_mae_history))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKy6OsDQ2VE3"
      },
      "source": [
        "#probamos la red entrenada en posiciones determinadas\n",
        "x = [1,.5,2,4,-2]#Introducir las posiciones en formato de arreglo\n",
        "y = [2,1,-1,.79,-2]\n",
        "z = [0,0,0,0,0]\n",
        "delays_UnaPos, XYZ_UnaPos= delays_testeo(x,y,z)\n",
        "np.savetxt('/content/drive/My Drive/RedGabo_Felipe & Constanza/delays_UnaPos.txt', delays_UnaPos,fmt = '%10.5f') #/content/drive/My Drive/XYZ.txt\n",
        "np.savetxt('/content/drive/MyDrive/RedGabo_Felipe & Constanza/XYZ_UnaPos.txt', XYZ_UnaPos,fmt = '%10.5f') #/content/drive/My Drive/XYZ.txt\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True) #para quitar la notación científica\n",
        "\n",
        "# definir el vector de los delays\n",
        "selected_data=np.loadtxt('/content/drive/MyDrive/RedGabo_Felipe & Constanza/delays_UnaPos.txt')\n",
        "xyz=model.predict(selected_data) #pasamos los datos por la red\n",
        "print('Posiciones predecidas')\n",
        "print('delays',selected_data.shape)\n",
        "print(xyz)\n",
        "\n",
        "pos_reales=np.loadtxt('/content/drive/MyDrive/RedGabo_Felipe & Constanza/XYZ_UnaPos.txt')\n",
        "print()\n",
        "print('Posiciones reales')\n",
        "print('pos',pos_reales.shape)\n",
        "print(pos_reales)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}